{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9803adf-0464-4a51-b56e-2b04b6e07f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nibabel in /Users/domen/mypython/lib/python3.9/site-packages (5.0.1)\n",
      "Requirement already satisfied: scipy in /Users/domen/mypython/lib/python3.9/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy in /Users/domen/mypython/lib/python3.9/site-packages (1.26.2)\n",
      "Requirement already satisfied: tensorflow in /Users/domen/mypython/lib/python3.9/site-packages (2.16.1)\n",
      "Requirement already satisfied: keras in /Users/domen/mypython/lib/python3.9/site-packages (3.1.1)\n",
      "Requirement already satisfied: matplotlib in /Users/domen/mypython/lib/python3.9/site-packages (3.6.0)\n",
      "Requirement already satisfied: opencv-python in /Users/domen/mypython/lib/python3.9/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: packaging>=17 in /Users/domen/mypython/lib/python3.9/site-packages (from nibabel) (23.1)\n",
      "Requirement already satisfied: setuptools in /Users/domen/mypython/lib/python3.9/site-packages (from nibabel) (67.8.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (2.29.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: rich in /Users/domen/mypython/lib/python3.9/site-packages (from keras) (13.5.2)\n",
      "Requirement already satisfied: namex in /Users/domen/mypython/lib/python3.9/site-packages (from keras) (0.0.7)\n",
      "Requirement already satisfied: optree in /Users/domen/mypython/lib/python3.9/site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/domen/mypython/lib/python3.9/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/domen/mypython/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/domen/mypython/lib/python3.9/site-packages (from matplotlib) (4.34.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/domen/mypython/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/domen/mypython/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/domen/mypython/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/domen/mypython/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/domen/mypython/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/domen/mypython/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/domen/mypython/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/domen/mypython/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/domen/mypython/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/domen/mypython/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/domen/mypython/lib/python3.9/site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/domen/mypython/lib/python3.9/site-packages (from rich->keras) (2.13.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/domen/mypython/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/domen/mypython/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/domen/mypython/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/domen/mypython/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (3.15.0)\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nibabel scipy numpy tensorflow keras matplotlib opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51f57462-3aa0-4caf-8976-b828430764dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf  # for data preprocessing\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29f2c9ee-60c4-4daf-b697-affff92dda86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nifti_file(filepath):\n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    # Read file\n",
    "    scan = nib.load(filepath)\n",
    "    # Get raw data\n",
    "    scan = scan.get_fdata()\n",
    "    print(scan.shape)\n",
    "    return scan\n",
    "\n",
    "\n",
    "def normalize(volume):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "    min = -1000\n",
    "    max = 400\n",
    "    volume[volume < min] = min\n",
    "    volume[volume > max] = max\n",
    "    volume = (volume - min) / (max - min)\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume\n",
    "\n",
    "\n",
    "def resize_volume(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = 250\n",
    "    desired_width = 350\n",
    "    desired_height = 350\n",
    "    # Get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Rotate\n",
    "    #img = ndimage.rotate(img, 90, reshape=False)\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_scan(path):\n",
    "    \"\"\"Read and resize volume\"\"\"\n",
    "    # wrap all of this into try except block\n",
    "    try:\n",
    "        # Read scan\n",
    "        volume = read_nifti_file(path)\n",
    "        # Normalize\n",
    "        volume = normalize(volume)\n",
    "        # Resize width, height and depth\n",
    "        volume = resize_volume(volume)\n",
    "        return volume\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505f7ec6-7ef5-4c76-b2b8-5bb122884061",
   "metadata": {},
   "source": [
    "Reading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b9cf253-e1cb-4310-89cf-ae29c71d63d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT scans with normal lung tissue: 4\n"
     ]
    }
   ],
   "source": [
    "scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"sample\", x)\n",
    "    for x in os.listdir(\"sample\")\n",
    "]\n",
    "\n",
    "print(\"CT scans with normal lung tissue: \" + str(len(scan_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3ad86f0-e871-4afe-8c02-ad3467b7cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from scipy import ndimage\n",
    "\n",
    "def rotate(volume):\n",
    "    \"\"\"Rotate the volume by a few degrees\"\"\"\n",
    "\n",
    "    def scipy_rotate(volume):\n",
    "        # define some rotation angles\n",
    "        angles = [-20, -10, -5, 5, 10, 20]\n",
    "        # pick angles at random\n",
    "        angle = random.choice(angles)\n",
    "        # rotate volume\n",
    "        #volume = ndimage.rotate(volume, angle, reshape=False)\n",
    "        volume[volume < 0] = 0\n",
    "        volume[volume > 1] = 1\n",
    "        return volume\n",
    "\n",
    "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
    "    return augmented_volume\n",
    "\n",
    "\n",
    "def train_preprocessing(volume, label):\n",
    "    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n",
    "    # Rotate volume\n",
    "    #volume = rotate(volume)\n",
    "    #volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, label\n",
    "\n",
    "\n",
    "def validation_preprocessing(volume, label):\n",
    "    \"\"\"Process validation data by only adding a channel.\"\"\"\n",
    "    #volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f41d3276-0666-4bff-a639-e9f66926dc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 400, 326)\n",
      "(400, 400, 305)\n",
      "(400, 400, 326)\n",
      "(400, 400, 305)\n",
      "(400, 400, 326)\n",
      "(400, 400, 305)\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "[0, 1]\n",
      "{0, 1}\n",
      "{1}\n",
      "[0]\n",
      "Number of samples in train are 1\n"
     ]
    }
   ],
   "source": [
    "# Read and process the scans.\n",
    "# Each scan is resized across height, width, and depth and rescaled.\n",
    "# ct_scans = np.array([process_scan(path + '/CT.nii.gz') for path in scan_paths])\n",
    "# pet_scans = np.array([process_scan(path + '/PET.nii.gz') for path in scan_paths])\n",
    "# mask_scans = np.array([process_scan(path + '/MASK.nii.gz') for path in scan_paths])\n",
    "\n",
    "ct_scans_list = [\n",
    "    process_scan(path + \"/CT.nii.gz\") for path in scan_paths[:2]\n",
    "]\n",
    "pet_scans_list = [\n",
    "    process_scan(path + \"/PET.nii.gz\")\n",
    "    for path in scan_paths[:2]\n",
    "]\n",
    "mask_scans_list = [\n",
    "    process_scan(path + \"/MASK.nii.gz\")\n",
    "    for path in scan_paths[:2]\n",
    "]\n",
    "ct_scans_not_none = [i for i, x in enumerate(ct_scans_list) if x is not None]\n",
    "pet_scans_not_none = [i for i, x in enumerate(pet_scans_list) if x is not None]\n",
    "mask_scans_not_none = [i for i, x in enumerate(mask_scans_list) if x is not None]\n",
    "print(ct_scans_not_none)\n",
    "print(pet_scans_not_none)\n",
    "print(mask_scans_not_none)\n",
    "\n",
    "ok_indices = set(ct_scans_not_none) & set(pet_scans_not_none) & set(mask_scans_not_none)\n",
    "print(ok_indices)\n",
    "ct_scans_list = [None, ct_scans_list[1]]\n",
    "ct_scans_not_done = [i for i, x in enumerate(ct_scans_list) if x is not None]\n",
    "ok_indices = set(ct_scans_not_done) & set(pet_scans_not_none) & set(mask_scans_not_none)\n",
    "print(ok_indices)\n",
    "ct_scans = np.array([ct_scans_list[i] for i in list(ok_indices)])\n",
    "pet_scans = np.array([pet_scans_list[i] for i in list(ok_indices)])\n",
    "mask_scans = np.array([mask_scans_list[i] for i in list(ok_indices)])\n",
    "# For the CT scans having presence of viral pneumonia\n",
    "# assign 1, for the normal ones assign 0.\n",
    "normal_labels = np.array([0 for _ in range(len(ct_scans))])\n",
    "print(normal_labels)\n",
    "\n",
    "# Split data in the ratio 70-30 for training and validation.\n",
    "\n",
    "x_ct = ct_scans\n",
    "y_ct = normal_labels\n",
    "x_pet = pet_scans\n",
    "y_pet = normal_labels\n",
    "x_mask = mask_scans\n",
    "y_mask = normal_labels\n",
    "print(\n",
    "    \"Number of samples in train are %d\"\n",
    "    % (x_ct.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ccb59ca1-8f7d-42a6-a98e-d6257f2882a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 20:45:24.985844: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Define data loaders.\n",
    "ct_loader = tf.data.Dataset.from_tensor_slices((x_ct, y_ct))\n",
    "pet_loader = tf.data.Dataset.from_tensor_slices((x_pet, y_pet))\n",
    "mask_loader = tf.data.Dataset.from_tensor_slices((x_mask, y_mask))\n",
    "print(len(list(ct_loader.map(train_preprocessing).batch(1))))\n",
    "\n",
    "batch_size = 1\n",
    "# Augment the on the fly during training.\n",
    "ct_dataset = (\n",
    "    ct_loader#.shuffle(len(x_train))\n",
    "    .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(4)\n",
    ")\n",
    "pet_dataset = (\n",
    "    pet_loader#.shuffle(len(x_train))\n",
    "    .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")\n",
    "mask_dataset = (\n",
    "    mask_loader#.shuffle(len(x_train))\n",
    "    .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1e5672-04b6-4948-b87a-f0cc426c9485",
   "metadata": {},
   "source": [
    "Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b270686-932d-4fca-b065-f6a34a7ca874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 20:47:37.189121: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-03-26 20:47:37.386639: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 20:47:38.895080: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-03-26 20:47:39.782435: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the CT scan is: (350, 350, 250)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 114\u001b[0m\n\u001b[1;32m    111\u001b[0m mask \u001b[38;5;241m=\u001b[39m masks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimension of the CT scan is:\u001b[39m\u001b[38;5;124m\"\u001b[39m, ct\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 114\u001b[0m \u001b[43mplot_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m700\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m700\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mix\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[52], line 25\u001b[0m, in \u001b[0;36mplot_slices\u001b[0;34m(num_rows, num_columns, width, height, data_ct, data_pet, data_mask, i)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m250\u001b[39m, step):\n\u001b[0;32m---> 25\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m[b][c]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.71428575\u001b[39m:\n\u001b[1;32m     26\u001b[0m                 s\u001b[38;5;241m.\u001b[39madd(b)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(s)\n",
      "File \u001b[0;32m~/mypython/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/mypython/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/mypython/lib/python3.9/site-packages/tensorflow/python/ops/tensor_getitem_override.py:256\u001b[0m, in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    254\u001b[0m   var_empty \u001b[38;5;241m=\u001b[39m constant_op\u001b[38;5;241m.\u001b[39mconstant([], dtype\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m    255\u001b[0m   packed_begin \u001b[38;5;241m=\u001b[39m packed_end \u001b[38;5;241m=\u001b[39m packed_strides \u001b[38;5;241m=\u001b[39m var_empty\n\u001b[0;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrided_slice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_begin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_strides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mypython/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/mypython/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/mypython/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:1096\u001b[0m, in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strides \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m   strides \u001b[38;5;241m=\u001b[39m ones_like(begin)\n\u001b[0;32m-> 1096\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrided_slice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1108\u001b[0m parent_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mypython/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:10931\u001b[0m, in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m  10930\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m> 10931\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10932\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStridedSlice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbegin_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10933\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbegin_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mellipsis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mellipsis_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10934\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_axis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_axis_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshrink_axis_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshrink_axis_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  10935\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m  10936\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "\n",
    "def plot_slices(num_rows, num_columns, width, height, data_ct, data_pet, data_mask, i):\n",
    "    image_axis = 2\n",
    "    mask = data_mask\n",
    "    ct = data_ct\n",
    "    pet = data_pet\n",
    "\n",
    "    #sagital_image = image[60, :, :] # Axis 0\n",
    "    \n",
    "    #axial_image = image[:, :, 30] # Axis 2\n",
    "    #coronal_image = image[:, 60, :] # Axis 1\n",
    "    \n",
    "    step = 5\n",
    "    coords = np.where(mask > 0.71428575)\n",
    "    s = set(coords[1][coords[1]%step == 0])\n",
    "    print(s)\n",
    "    coords = np.where(mask > 0.71428575)\n",
    "    print(coords)\n",
    "\n",
    "    plt.figure(figsize=(350, 250))\n",
    "    plt.style.use('grayscale')\n",
    "    if len(list(s)) == 0:\n",
    "        s.add(175)\n",
    "    for j in range(len(list(s))):\n",
    "        sagital_ct=ct[:,list(s)[j],:] * 0.1\n",
    "        sagital_mask=mask[:,list(s)[j],:]\n",
    "        sagital_pet=pet[:,list(s)[j],:]\n",
    "        cmap1 = plt.cm.viridis  # Choose the colormap for image1\n",
    "        cmap2 = plt.cm.inferno\n",
    "        sagital_ct_jet = cmap1(sagital_ct)[:,:,2]\n",
    "        sagital_pet_gray = cmap2(sagital_pet)[:,:,2]\n",
    "    \n",
    "        print(sagital_ct[60,30])\n",
    "        comb = (0.01 * sagital_ct_jet) + (0.99 * sagital_pet_gray)\n",
    "        plt.imsave('combined'+str(i)+str(j)+'.png',np.rot90(comb))\n",
    "        \n",
    "    #plt.savefig('combined.png')\n",
    "\n",
    "    # for i in range(1, 2):\n",
    "    #     for j in range(1, 5, 4):\n",
    "            # sagital_ct=ct[:,list(s)[0]+(i-1)*(j-1)+j-1,:] * 0.1\n",
    "            # sagital_mask=mask[:,list(s)[0]+(i-1)*(j-1)+j-1,:]\n",
    "            # sagital_pet=pet[:,list(s)[0]+(i-1)*(j-1)+j-1,:]\n",
    "            # plt.subplot(i,5,j)\n",
    "            # plt.imshow(np.rot90(sagital_ct), cmap='viridis')\n",
    "            # plt.title('Sagital Plane')\n",
    "\n",
    "            \n",
    "            # plt.axis('off')\n",
    "            # plt.subplot(i,5,j+1)\n",
    "            # plt.imshow(np.rot90(sagital_mask))\n",
    "            # plt.title('Sagital Plane')\n",
    "            # plt.axis('off')\n",
    "\n",
    "            # plt.axis('off')\n",
    "            # plt.subplot(i,5,j+2)\n",
    "            # plt.imshow(np.rot90(sagital_pet))\n",
    "            # plt.imshow(np.rot90(sagital_pet))\n",
    "            # plt.title('Sagital Plane')\n",
    "            # plt.axis('off')\n",
    "\n",
    "            # cmap1 = plt.cm.viridis  # Choose the colormap for image1\n",
    "            # cmap2 = plt.cm.inferno\n",
    "            # sagital_ct_jet = cmap1(sagital_ct)[:,:,2]\n",
    "            # sagital_pet_gray = cmap2(sagital_pet)[:,:,2]\n",
    "\n",
    "            # print(sagital_ct[60,30])\n",
    "            # comb = (0.01 * sagital_ct_jet) + (0.99 * sagital_pet_gray)\n",
    "            # plt.axis('off')\n",
    "            # plt.subplot(i,5,j+3)\n",
    "            # plt.imshow(np.rot90(comb))\n",
    "            # plt.title('Sagital Plane')\n",
    "            # plt.axis('off')\n",
    "\n",
    "\n",
    "    # plt.subplot(142)\n",
    "    # plt.imshow(np.rot90(axial_image))\n",
    "    # plt.title('Axial Plane')\n",
    "    # plt.axis('off')\n",
    "\n",
    "    # plt.subplot(143)\n",
    "    # plt.imshow(np.rot90(coronal_image))\n",
    "    # plt.title('Coronal Plane')\n",
    "    # plt.axis('off')\n",
    "\n",
    "ct_d = ct_dataset\n",
    "pet_d = pet_dataset\n",
    "mask_d = mask_dataset\n",
    "print(len(list(ct_d)))\n",
    "for ix in range(0, 2):\n",
    "    cts, labels = list(ct_d)[ix]\n",
    "    pets, labels1 = list(pet_d)[ix]\n",
    "    masks, labels2 = list(mask_d)[ix]\n",
    "    \n",
    "    cts = cts.numpy()\n",
    "    ct = cts[0]\n",
    "    pets = pets.numpy()\n",
    "    pet = pets[0]\n",
    "    mask = masks.numpy()\n",
    "    mask = masks[0]\n",
    "    print(\"Dimension of the CT scan is:\", ct.shape)\n",
    "    \n",
    "    plot_slices(4, 10, 700, 700, ct, pet, mask, ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9cb0c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{185, 195, 180, 190}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m250\u001b[39m, step):\n\u001b[0;32m---> 15\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmask\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m0.71428575\u001b[39;49m:\n\u001b[1;32m     16\u001b[0m                 s\u001b[38;5;241m.\u001b[39madd(b)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(s)\n",
      "File \u001b[0;32m~/mypython/lib/python3.9/site-packages/tensorflow/python/ops/tensor_math_operator_overrides.py:149\u001b[0m, in \u001b[0;36m_promote_dtypes_decorator.<locals>.wrapper\u001b[0;34m(x, y, *args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(x, y, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 149\u001b[0m   x, y \u001b[38;5;241m=\u001b[39m \u001b[43moverride_binary_operator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_promote_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(x, y, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/mypython/lib/python3.9/site-packages/tensorflow/python/framework/override_binary_operator.py:46\u001b[0m, in \u001b[0;36mmaybe_promote_tensors\u001b[0;34m(force_same_dtype, *tensors)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot determine dtype.  Got sequence \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmaybe_promote_tensors\u001b[39m(\u001b[38;5;241m*\u001b[39mtensors, force_same_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     47\u001b[0m   \u001b[38;5;124;03m\"\"\"Promotes tensors if numpy style promotion is enabled.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m  This function promotes `tensors` according to numpy promotion rules\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    The promoted list of tensors.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step = 5\n",
    "coords = np.where(mask > 0.71428575)\n",
    "filtered_b = set(coords[1][coords[1]%step == 0])\n",
    "print(filtered_b)\n",
    "step=5\n",
    "brk=0\n",
    "s = set()\n",
    "for a in range(0, 350, step):\n",
    "    if brk:\n",
    "        break\n",
    "    for b in range(0, 350, step):\n",
    "        if brk:\n",
    "            break\n",
    "        for c in range(0, 250, step):\n",
    "            if mask[a][b][c]>0.71428575:\n",
    "                s.add(b)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce413310-108a-4b58-a2c5-ea6228c68cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
