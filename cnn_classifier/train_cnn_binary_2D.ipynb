{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recimo da ze imamo slike za training in validation\n",
    "import os\n",
    "\n",
    "train_dir_name = \"/image_slicing/train/\"\n",
    "validation_dir_name = \"/image_slicing/validation/\"\n",
    "\n",
    "train_positive_dir = os.path.join(train_dir_name + \"positive\")\n",
    "train_negative_dir = os.path.join(train_dir_name + \"negative\")\n",
    "\n",
    "validation_positive_dir = os.path.join(validation_dir_name + \"positive\")\n",
    "validation_negative_dir = os.path.join(validation_dir_name + \"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print total length of each dataset\n",
    "print('total training positive images:', len(os.listdir(train_positive_dir)))\n",
    "print('total training negative images:', len(os.listdir(train_negative_dir)))\n",
    "print('total validation positive images:', len(os.listdir(validation_positive_dir)))\n",
    "print('total validation negative images:', len(os.listdir(validation_negative_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing needs to be done:\n",
    "preprocessing_needed = True\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "    # All images will be rescaled by 1./255\n",
    "\n",
    "if preprocessing_needed:\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir_name,\n",
    "        # target_size=(200, 200), # to be discussed?\n",
    "        batch_size=120,\n",
    "        class_mode='binary')\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir_name,\n",
    "        # target_size=(200, 200), # to be discussed?\n",
    "        batch_size=19,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (200, 200, 3) #??\n",
    "\n",
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = img_shape),\n",
    "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "                                    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Model checkpoints!! https://keras.io/api/callbacks/model_checkpoint/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BEFORE:\n",
    "# history = model.fit(train_generator,\n",
    "#       steps_per_epoch=8,\n",
    "#       epochs=15,\n",
    "#       verbose=1,\n",
    "#       validation_data = validation_generator,\n",
    "#       validation_steps=8)\n",
    "\n",
    "# AFTER:\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "# Checkpoint directory\n",
    "checkpoint_dir = \"/image_slicing/checkpoints/\"\n",
    "\n",
    "# Create directory if it does not exist\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "checkpoint_path = \"checkpoints/model_{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "# Create a ModelCheckpoint callback\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                             save_best_only=True,  # Save only the best model\n",
    "                             monitor='val_loss',   # Monitor the validation loss\n",
    "                             mode='min',           # Minimize the validation loss\n",
    "                             verbose=1)            # Print out when a model is being saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=8,\n",
    "                    epochs=15,\n",
    "                    verbose=1,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=8,\n",
    "                    callbacks=[checkpoint]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample evaluation before exit.\n",
    "model.evaluate(validation_generator)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
